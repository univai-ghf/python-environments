{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Environments\n",
    "\n",
    "This notebook documents the commands we will be using in this workshop. For more documentation please see slides.pdf in the same folder.\n",
    "\n",
    "We are working on mybinder.org. Click this link: [https://mybinder.org/v2/gh/univai-ghf/python-environments/HEAD](https://mybinder.org/v2/gh/univai-ghf/python-environments/HEAD) to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTIVITY 1: Creating a virtual environment\n",
    "\n",
    "- `conda create --name environment-name [python=3.6]`\n",
    "- `conda activate environment-name`\n",
    "- `conda deactivate environment-name`\n",
    "- `conda install <packagename>`\n",
    "\n",
    "Eg:\n",
    "\n",
    "```\n",
    "conda create -n newe\n",
    "conda activate newe\n",
    "conda install numpy pandas ipykernel\n",
    "conda deactivate newe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure environments are available on jupyterlab\n",
    "\n",
    "- in the base installation, make sure you `conda install nb_conda_kernels`.\n",
    "- this will depend on how you installed the base. But run the above command is needed\n",
    "- in our binder system, this is already installed.\n",
    "- now in every new environment make sure you install `ipykernel`.\n",
    "\n",
    "\n",
    "![inline](images/newe.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Capturing a virtual environment\n",
    "\n",
    "`conda env export` will capture the exact dependencies. You can now redirect into a file, and use elsewhere on the same OS to recreate this environment.\n",
    "\n",
    "The file is usually called `environment.yml`, so we do:\n",
    "\n",
    "`conda env export > environment.yml`\n",
    "\n",
    "If this file is in a particular folder, just type `conda env create` to create an environment with these packages.\n",
    "\n",
    "---\n",
    "\n",
    "## ACTIVITY 2: Using environment.yml files\n",
    "\n",
    "- you can write your own `environment.yml` file to be much less tied to specific package versions, unless needed.\n",
    "\n",
    "For example, for an environment `newe2`, we create a folder `newe2`, and in that folder, we create a `environment.yml` with the contents:\n",
    "\n",
    "```yaml\n",
    "name: newe2\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- numpy\n",
    "- scipy\n",
    "- seaborn\n",
    "- scikit-learn\n",
    "- tensorflow\n",
    "- keras\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## A conda env per project\n",
    "\n",
    "- create a conda environment for each new project\n",
    "- put an `environment.yml` in each project folder (like `newe2`) with a `name` line reflecting the folder name\n",
    "- `conda|mamba env create` in project folder (like `newe2`)\n",
    "- if not per project, at least have one for each new class, or class of projects\n",
    "- environment for class of projects may grow organically, but capture its requirements from time-to-time.\n",
    "- for example, on my dual-gpu machine, I have 3 separate environments for pytorch, tensorflow, and jax, as they even had slightly different CUDA requirements.\n",
    "\n",
    "see [here](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Mamba\n",
    "\n",
    "- mamba is a version of conda that works with conda but is faster.\n",
    "- use `mamba` to create and/or install\n",
    "- use `conda` to activate/deactivate\n",
    "- See [https://mamba.readthedocs.io/en/latest/user_guide/mamba.html](https://mamba.readthedocs.io/en/latest/user_guide/mamba.html)\n",
    "- on our binder environment I can issue `mamba env create`. Its faster. But then I must use `conda activate newe2` to startup the new environment\n",
    "- by default conda will use both default and conda-forge channels, mamba will use conda-forge. I found keras currently only installable with mamba.\n",
    "\n",
    "---\n",
    "\n",
    "## What we will do, exactly\n",
    "\n",
    "1. `cd newe2`\n",
    "2. `mamba env create`\n",
    "3. `conda activate newe2`\n",
    "4. run notebook `keras_perceptron.ipynb`\n",
    "5. run python file `keras_perceptron.py`\n",
    "6. `conda deactivate newe2`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```yaml\n",
    "# file name: environment.yml\n",
    "\n",
    "# Give your project an informative name\n",
    "name: project-name\n",
    "\n",
    "# Specify the conda channels that you wish to grab packages from, in order of priority.\n",
    "channels:\n",
    "- defaults\n",
    "- conda-forge\n",
    "\n",
    "# Specify the packages that you would like to install inside your environment. \n",
    "#Version numbers are allowed, and conda will automatically use its dependency \n",
    "#solver to ensure that all packages work with one another.\n",
    "dependencies:\n",
    "- python=3.7\n",
    "- conda\n",
    "- scipy\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "\n",
    "# There are some packages which are not conda-installable. You can put the pip dependencies here instead.\n",
    "- pip:\n",
    "    - tqdm  # for example only, tqdm is actually available by conda.\n",
    "```\n",
    "\n",
    "( from http://ericmjl.com/blog/2018/12/25/conda-hacks-for-data-science-efficiency/)\n",
    "\n",
    "---\n",
    "\n",
    "## More information\n",
    "\n",
    "- https://carpentries-incubator.github.io/introduction-to-conda-for-data-scientists/\n",
    "- https://goodresearch.dev/setup.html , which is part of the excellent book\n",
    "- https://goodresearch.dev/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Importance of Structure\n",
    "\n",
    "- one might as well use the one env per project ot set-of-projects structure to organize work\n",
    "- it is really important to organize your data science work well\n",
    "- a good tool for this is `cookiecutter`, which sets up a template folder structure for you. Install by `pip install cookiecutter` in your base.\n",
    "- you install a cookiecutter by doing `cookiecutter source`.\n",
    "\n",
    "---\n",
    "\n",
    "## Two nice cookiecutters\n",
    "\n",
    "- https://github.com/patrickmineault/true-neutral-cookiecutter\n",
    "- Install via: `cookiecutter gh:patrickmineault/true-neutral-cookiecutter`\n",
    "- https://drivendata.github.io/cookiecutter-data-science/\n",
    "- Install via: `cookiecutter gh:drivendata/cookiecutter-data-science`\n",
    "\n",
    "---\n",
    "\n",
    "## True Neutral Cookiecutter\n",
    "\n",
    "```\n",
    "├── data\n",
    "├── doc\n",
    "├── results\n",
    "├── scripts\n",
    "├── src\n",
    "│   └── __init__.py\n",
    "├── tests\n",
    "├── .gitignore\n",
    "├── environment.yml\n",
    "├── README.md\n",
    "└── setup.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ACTIVITY 3: An example\n",
    "\n",
    "- We do: `cookiecutter gh:patrickmineault/true-neutral-cookiecutter`\n",
    "- name the project perceptron\n",
    "- create the conda environment:\n",
    "- `conda create --name perceptron; conda activate perceptron; mamba install ipykernel numpy tensorflow keras` or do `mamba env create` with an appropriate environment file\n",
    "- `cd perceptron`\n",
    "- then do `pip install -e .` which creates the src directory loadable into python\n",
    "\n",
    "---\n",
    "\n",
    "## ACTIVITY 3: copy files over\n",
    "\n",
    "In the perceptron folder:\n",
    "\n",
    "- `cp ../perceptronfiles/perceptron.ipynb scripts/`\n",
    "- `cp ../perceptronfiles/config.py src/`\n",
    "\n",
    "Now run the notebook\n",
    "\n",
    "---\n",
    "\n",
    "## Best practices for use\n",
    "\n",
    "- now we can do development with both the notebook and files. In a notebook cell put the following to have the notebook automatically reload the file when it changes.\n",
    "\n",
    "```\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```\n",
    "\n",
    "- refactor anything repeated multiple times to python files with functions in them. Notebooks should be very readable\n",
    "- output all intermediate files into `data` or `results` while writing your pipelines: files from train test splits, parameter values and results, etc\n",
    "- future you will thank the current you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1-arm64",
   "language": "python",
   "name": "ml1-arm64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
